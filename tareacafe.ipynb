{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tareacafe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B50eerdPZTHE",
        "colab_type": "code",
        "outputId": "67ed01dc-3f14-4036-afb8-70b0ece815e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOIW09rxZotI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os, sys, math\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "import itertools\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "img_width, img_height = 80, 80\n",
        "\n",
        "train_data_dir = 'drive/My Drive/Colab Notebooks/data/train/'\n",
        "\n",
        "validation_data_dir = 'drive/My Drive/Colab Notebooks/data/validation/'\n",
        "test_data_dir = 'drive/My Drive/Colab Notebooks/data/test/'\n",
        "nb_train_samples = 560#stepporepoch\n",
        "nb_validation_samples = 120 #validation steps\n",
        "epochs = 20\n",
        "batch_size = 50\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnhBmhF3Z3JW",
        "colab_type": "code",
        "outputId": "da1fa5f2-73b9-4e9b-f0df-a9bbc42a2c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "top_model_weights_path = 'CompletModelCafe3.h5'\n",
        "#model.load_weights(top_model_weights_path)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator( rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen  = ImageDataGenerator( rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( train_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory( validation_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='categorical')\n",
        "\n",
        "history=model.fit_generator( train_generator, steps_per_epoch=nb_train_samples // batch_size, epochs=epochs,  validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size)\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 560 images belonging to 2 classes.\n",
            "Found 120 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "11/11 [==============================] - 8s 719ms/step - loss: 0.8930 - acc: 0.4787 - val_loss: 0.6914 - val_acc: 0.5100\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 7s 664ms/step - loss: 0.6988 - acc: 0.5152 - val_loss: 0.6900 - val_acc: 0.5286\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 7s 655ms/step - loss: 0.6946 - acc: 0.5141 - val_loss: 0.6923 - val_acc: 0.4857\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 7s 656ms/step - loss: 0.7037 - acc: 0.4940 - val_loss: 0.7044 - val_acc: 0.4900\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 7s 663ms/step - loss: 0.6912 - acc: 0.5469 - val_loss: 0.6939 - val_acc: 0.4857\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 7s 656ms/step - loss: 0.7139 - acc: 0.5403 - val_loss: 0.6868 - val_acc: 0.5429\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 8s 707ms/step - loss: 0.6938 - acc: 0.5727 - val_loss: 0.6825 - val_acc: 0.5400\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 7s 598ms/step - loss: 0.6818 - acc: 0.5553 - val_loss: 0.6556 - val_acc: 0.6143\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 8s 705ms/step - loss: 0.7945 - acc: 0.6382 - val_loss: 0.6273 - val_acc: 0.7143\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 7s 653ms/step - loss: 0.6603 - acc: 0.5897 - val_loss: 0.6801 - val_acc: 0.5100\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 7s 631ms/step - loss: 0.6511 - acc: 0.6092 - val_loss: 0.5670 - val_acc: 0.7857\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 7s 613ms/step - loss: 0.6424 - acc: 0.6980 - val_loss: 0.6349 - val_acc: 0.5857\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 7s 638ms/step - loss: 0.6076 - acc: 0.6591 - val_loss: 0.6455 - val_acc: 0.6100\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 7s 660ms/step - loss: 0.7269 - acc: 0.5867 - val_loss: 0.6335 - val_acc: 0.7143\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 8s 692ms/step - loss: 0.6251 - acc: 0.6309 - val_loss: 0.4636 - val_acc: 0.8714\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 7s 634ms/step - loss: 0.6293 - acc: 0.6864 - val_loss: 0.4650 - val_acc: 0.7800\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 8s 720ms/step - loss: 0.6080 - acc: 0.6655 - val_loss: 0.7410 - val_acc: 0.6286\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 7s 657ms/step - loss: 0.6419 - acc: 0.6549 - val_loss: 0.4687 - val_acc: 0.7714\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 7s 618ms/step - loss: 0.6805 - acc: 0.7111 - val_loss: 0.4919 - val_acc: 0.8300\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 7s 647ms/step - loss: 0.5809 - acc: 0.7098 - val_loss: 0.5077 - val_acc: 0.7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKHXclKHXlmF",
        "colab_type": "code",
        "outputId": "ab04614e-84c4-4869-cbd8-26bfcb477f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "def plots(ims,figsize=(80,80),rows=1,interp=False,titles=None):\n",
        "  if(type(ims[0])is np.ndarray):\n",
        "    ims=np.array(ims).astype(np.uint8)\n",
        "    if(ims.shape[-1]!=3):\n",
        "      ims=ims.transpose((0,2,3,1))\n",
        "  f=plt.figure(figsize=figsize)\n",
        "  cols=len(ims)//rows if len(ims)%2==0 else len(ims)//rows+1\n",
        "  for i in range(len(ims)):\n",
        "    sp=f.add_subplot(rows,cols,i+1)\n",
        "    sp.axis('Off')\n",
        "    if titles is not None:\n",
        "      sp.set_title(titles[i],fontsize=16)\n",
        "      \n",
        "    plt.imshow(ims[i],interpolation=None if interp else 'none')\n",
        "###############\n",
        "test_baches=ImageDataGenerator().flow_from_directory(validation_data_dir,target_size=(80,80),classes=['class1','class2'],batch_size=10)\n",
        "test_imgs,test_labels=next(test_baches)\n",
        "predictions=model.predict_generator(test_baches,steps=1,verbose=0)\n",
        "\n",
        "for i in predictions:\n",
        "  print(int(i[0]))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 120 images belonging to 2 classes.\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}